{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from model import BaseLineUnet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataset import GoProDataset\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure, LearnedPerceptualImagePatchSimilarity\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = BaseLineUnet()\n",
    "model.to(device)\n",
    "checkpoint = torch.load(\"lightning_logs/version_14/checkpoints/best-checkpoint-epoch=267-train_loss=0.047806.ckpt\")\n",
    "model_weights = checkpoint[\"state_dict\"]\n",
    "for key in list(model_weights):\n",
    "    model_weights[key.replace(\"model.\", \"\")] = model_weights.pop(key)\n",
    "for key in list(model_weights):\n",
    "    if key.startswith(\"loss_fn.\"):\n",
    "        model_weights.pop(key)\n",
    "model.load_state_dict(model_weights)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GoProDataset(root_dir='A', mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_img_inference_to_file(img_tensor, sharp_tensor, index):\n",
    "    to_PIL = v2.ToPILImage()\n",
    "    to_PIL(img_tensor).save(f'output/{index}blur.png')\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    if sharp_tensor is not None:\n",
    "        sharp_tensor = sharp_tensor.unsqueeze(0)\n",
    "    B, C, H, W = img_tensor.shape\n",
    "    pad_h = 256 - (H % 256) if H % 256 != 0 else 0\n",
    "    pad_w = 256 - (W % 256) if W % 256 != 0 else 0\n",
    "    img_tensor = F.pad(img_tensor, (0, pad_w, 0, pad_h))\n",
    "    out_tensor = torch.zeros_like(img_tensor, device=device)\n",
    "    with torch.inference_mode():\n",
    "        out_tensor = model(img_tensor)\n",
    "                \n",
    "    out_tensor = torch.clamp(out_tensor, 0, 1)\n",
    "    out_tensor = out_tensor[:, :, :out_tensor.shape[2]-pad_h, :out_tensor.shape[3]-pad_w]\n",
    "    \n",
    "    out_tensor = out_tensor.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    \n",
    "    img = to_PIL(out_tensor[0])\n",
    "    img.save(f'output/{index}predicted.png')\n",
    "    if sharp_tensor is not None:\n",
    "        sharp_tensor = sharp_tensor.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "        sharp = to_PIL(sharp_tensor[0])\n",
    "        sharp.save(f'output/{index}sharp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_folder_contents(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder {folder_path} does not exist.\")\n",
    "        return\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "            os.remove(item_path)\n",
    "            print(f\"Deleted file: {item_path}\")\n",
    "delete_folder_contents('output')\n",
    "os.makedirs('output', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(0, len(dataset)-1)\n",
    "x, y = dataset[index]\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "big_img_inference_to_file(x, y, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'aaa.jpg'\n",
    "if img != '':\n",
    "    img = Image.open(img)\n",
    "    img = img.convert('RGB')\n",
    "    to_tensor = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "\n",
    "    img = to_tensor(img)\n",
    "    img = img.to(device)\n",
    "\n",
    "    big_img_inference_to_file(img, None, 99999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
