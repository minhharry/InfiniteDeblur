{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model import BaseLineUnet\n",
    "from dataset import GoProDataset\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torchinfo import summary\n",
    "from torchvision.transforms import v2\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from NAFnet_baseline.Baseline_arch import Baseline\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_of_files():\n",
    "    files = []\n",
    "    files.extend(glob.glob(\"**/*.py\", recursive=True))\n",
    "    files.extend(glob.glob(\"**/*.ipynb\", recursive=True))\n",
    "    data = {}\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            text_content = f.read()\n",
    "        data[file] = text_content\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningWrapper(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = BaseLineUnet()\n",
    "        self.model_code = create_dict_of_files()\n",
    "        # img_channel = 3\n",
    "        # width = 32\n",
    "\n",
    "        # dw_expand = 1\n",
    "        # ffn_expand = 2\n",
    "\n",
    "        # enc_blks = [1, 1, 1, 28]\n",
    "        # middle_blk_num = 1\n",
    "        # dec_blks = [1, 1, 1, 1]\n",
    "\n",
    "        # self.model = Baseline(img_channel=img_channel, width=width, middle_blk_num=middle_blk_num,\n",
    "        #             enc_blk_nums=enc_blks, dec_blk_nums=dec_blks, dw_expand=dw_expand, ffn_expand=ffn_expand)\n",
    "    \n",
    "    def on_save_checkpoint(self, checkpoint):\n",
    "        checkpoint[\"model_code\"] = self.model_code\n",
    "\n",
    "    def on_load_checkpoint(self, checkpoint):\n",
    "        self.model_code = checkpoint[\"model_code\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 200, eta_min=1e-6)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,  \n",
    "                'interval': 'epoch',   \n",
    "                'frequency': 1,         \n",
    "                'monitor': 'train_loss',   \n",
    "                'strict': True        \n",
    "            }\n",
    "        }\n",
    "    \n",
    "model = LightningWrapper()\n",
    "summary(model, (16, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "train_dataset = GoProDataset('E:\\\\Downloads\\\\GOPRO_Large\\\\train', transform=transform, size=256)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=11, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor='train_loss', filename='best-checkpoint-{epoch:02d}-{train_loss:.4f}', save_last=True)\n",
    "lr_callback = LearningRateMonitor(logging_interval='epoch')\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "trainer = L.Trainer(max_epochs=200, precision='bf16-mixed', callbacks=[checkpoint_callback, lr_callback])\n",
    "trainer.fit(model, train_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
